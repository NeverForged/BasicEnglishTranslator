{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "import unicodedata\n",
    "import sys\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk.data\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(doc, vocabulary):\n",
    "    # It just splits the string on a space and then counts the number of times that terms happen. \n",
    "    bag_of_words = Counter(doc.split(' '))\n",
    "    # The counter object will be translated into a vector.\n",
    "    # And the next line creates a numpy vector with space for those entries. \n",
    "    doc_vector = np.zeros(len(vocabulary))\n",
    "    # The next for loop is very interesting. Although the doc may have words that are not in \n",
    "    # the vocabulary, it is only for words in the vocabulary that the vector is made. \n",
    "    # word_index is an integer and indexes the doc_vector. \n",
    "    for word_index, word in enumerate(vocabulary):\n",
    "        if word in bag_of_words:\n",
    "            doc_vector[word_index] += bag_of_words[word]\n",
    "    return doc_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other functions (combine?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Book:\n",
    "    \n",
    "    def __init__(self, book):\n",
    "        self.title = ''\n",
    "        self.author = ''\n",
    "        #             self.title = book[8].strip().replace('Title: ','')\n",
    "        #             self.author = book[1].strip()\n",
    "        #             self.region = book[4].strip()\n",
    "        #             self.lifespan = book[2].strip()\n",
    "        #             self.topics = [topic.strip() for topic in book[5].split(',')]\n",
    "        #             self.type = book[7]\n",
    "        #             self.text = \"\".join(book[11:])\n",
    "        #             self.clean_text = \"\"\n",
    "        #             self.author = book[10 .strip().replace('Author: ','')\n",
    "        n = len(book)\n",
    "        lim = 30\n",
    "        if lim > n:\n",
    "            lim = n\n",
    "        # Project Gutenburg has no way to determine front matter,\n",
    "        # so cut first 5% to avoid it\n",
    "        start = int(n - 0.95*n)\n",
    "        for line in book[:lim]:\n",
    "            if 'Title: ' in line:\n",
    "                self.title = line.strip().replace('Title: ','')\n",
    "            if 'Author: ' in line:\n",
    "                self.author = line.strip().replace('Author: ','')\n",
    "        # start set to strip off various lengths of front-matter\n",
    "        temp_text = \"\".join(book[start:]).decode('utf-8')\n",
    "        # -19350 to strip off the Project Gutenberg donation requests\n",
    "        self.text = temp_text[0:len(temp_text) - 19350]\n",
    "        self.clean_text = \"\"\n",
    "\n",
    "\n",
    "    def clean(self):\n",
    "        print 'Start cleaning...'\n",
    "        # Get rid of line breaks. \n",
    "        x = self.text.split(\"\\n\")\n",
    "        x = [i.strip() for i in x]\n",
    "        self.clean_text = \" \".join(x)\n",
    "\n",
    "        # Lower case.\n",
    "        self.clean_text = self.clean_text.lower()\n",
    "\n",
    "        # Remove punctuations\n",
    "        tbl = dict.fromkeys(i for i in xrange(sys.maxunicode)\n",
    "                  if unicodedata.category(unichr(i)).startswith('P'))\n",
    "        self.clean_text = self.clean_text.translate(tbl)\n",
    "\n",
    "        # Remove spaces.\n",
    "        self.clean_text = self.clean_text.replace(\"  \",\" \")\n",
    "        while \"  \" in self.clean_text:\n",
    "            self.clean_text = self.clean_text.replace(\"  \",\" \")\n",
    "        print '   ...done'\n",
    "\n",
    "    def lemmatize(self):\n",
    "        print 'Start lemmatize...'\n",
    "        # Lemmatize.\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        temp=\"\"\n",
    "        for word in self.clean_text.split():\n",
    "            temp=temp+\" \"+wordnet_lemmatizer.lemmatize(word)\n",
    "\n",
    "        self.clean_text = temp.strip() # get rid of white space. \n",
    "        print '   ...done'\n",
    "\n",
    "    def stem(self):\n",
    "        print \"Start stem...\"\n",
    "        from nltk.stem.porter import PorterStemmer\n",
    "        porter = PorterStemmer()\n",
    "        temp=\"\"\n",
    "        for word in self.clean_text.split():\n",
    "            temp=temp+\" \"+porter.stem(word)\n",
    "\n",
    "        self.clean_text = temp.strip() # get rid of white space.\n",
    "        print '   ...done'\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if index == 0:\n",
    "            return self.clean_text\n",
    "        if index == 1:\n",
    "            return self.title\n",
    "        if index == 2:\n",
    "            return self.author\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the corpus of books from a subdirectory. \n",
    "book_corpus = []\n",
    "author = 'dumas'\n",
    "for filename in os.listdir('./data/' + author):\n",
    "    if filename[-3:] == 'txt':\n",
    "        f = open('./data/' + author + '/' + filename)\n",
    "        book = Book(f.readlines())\n",
    "        f.close()\n",
    "        book_corpus.append(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1219477"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1238827 - 19350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3344865"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_corpus[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3344865"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_corpus[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he page confessed that he was no farther\n",
      "advanced than the day before; then the marquis scolded, threatened to\n",
      "take away his fine clothes, to withdraw his own promises, and finally to\n",
      "address himself to some other person. At this last threat the youth\n",
      "would again call up his courage, and promise to be bolder to-morrow; and\n",
      "on the morrow would spend the day in making a thousand compliments to\n",
      "his mistress’s eyes, which she, in her innocence, did not understand. At\n",
      "last, one day, Madame de Perrant asked him what made him look at her\n",
      "thus, and he ventured to confess his love; but then Madame de Perrant,\n",
      "changing her whole demeanour, assumed a face of sternness and bade him\n",
      "go out of her room.\n",
      "\n",
      "The poor lover obeyed, and ran, in despair, to confide his grief to the\n",
      "husband, who appeared sincerely to share it, but consoled him by saying\n",
      "that he had no doubt chosen his moment badly; that all women, even the\n",
      "least severe, had inauspicious hours in which they would not yield to\n",
      "attack, and that he must let a few days pass, which he must employ in\n",
      "making his peace, and then must take advantage of a better opportunity,\n",
      "and not allow himself to be rebuffed by a few refusals; and to these\n",
      "words the marquis added a purse of gold, in order that the page might,\n",
      "if necessary, win over the marquise’s waiting-woman.\n",
      "\n",
      "Guided thus by the older experience of the husband, the page began to\n",
      "appear very much ashamed and very penitent; but for a day or two the\n",
      "marquise, in spite of his apparent humility, kept him at a distance: at\n",
      "last, reflecting no doubt, with the assistance of her mirror and of her\n",
      "maid, that the crime was not absolutely unpardonable, and after having\n",
      "reprimanded the culprit at some length, while he stood listening with\n",
      "eyes cast down, she gave a him her hand, forgave him, and admitted him\n",
      "to her companionship as before.\n",
      "\n",
      "Things went on in this way for a week. The page no longer raised his\n",
      "eyes and did not venture to open his mouth, and the marquise was\n",
      "beginning to regret the time in which he used to look and to speak,\n",
      "when, one fine day while she was at her toilet, at which she had allowed\n",
      "him to be present, he seized a moment when the maid had left her alone,\n",
      "to cast himself at her feet and tell her that he had vainly tried to\n",
      "stifle his love, and that, even although he were to die under the weight\n",
      "of her anger, he must tell her that this love was immense, eternal,\n",
      "stronger than his life. The marquise upon this wished to send him away,\n",
      "as on the former occasion, but instead of obeying her, the page, better\n",
      "instructed, took her in his arms. The marquise called, screamed, broke\n",
      "her bell-rope; the waiting-maid, who had been bought over, according to\n",
      "the marquis’s advice, had kept the other women out of the way, and was\n",
      "careful not to come herself. Then the marquise, resisting force by\n",
      "force, freed herself from the page’s arms, rushed to her husband’s room,\n",
      "and there, bare-necked, with floating hair, and looking lovelier than\n",
      "ever, flung herself into his arms and begged his protection against the\n",
      "insolent fellow who had just insulted her. But what was the amazement of\n",
      "the marquise, when, instead of the anger which she expected to see break\n",
      "forth, the marquis answered coldly that what she was saying was\n",
      "incredible, that he had always found the young man very well behaved,\n",
      "and that, no doubt, having taken up some frivolous ground of resentment\n",
      "against him, she was employing this means to get rid of him; but, he\n",
      "added, whatever might be his love for her, and his desire to do\n",
      "everything that was agreeable to her, he begged her not to require this\n",
      "of him, the young man being his friend’s son, and consequently his own\n",
      "adopted child. It was now the marquise who, in her turn, retired\n",
      "abashed, not knowing what to make of such a reply, and fully resolving,\n",
      "since her husband’s protection failed her, to keep herself well guarded\n",
      "by her own severity.\n",
      "\n",
      "Indeed, from that moment the marquise behaved to the poor youth with so\n",
      "much prudery, that, loving her as he did, sincerely, he would have died\n",
      "of grief, if he had not had the marquis at hand to encourage and\n",
      "strengthen him. Nevertheless, the latter himself began to despair, and\n",
      "to be more troubled by the virtue of his wife than another man might\n",
      "have been by the levity of his. Finally, he resolved, seeing that\n",
      "matters remained at the same point and that the marquise did not relax\n",
      "in the smallest degree, to take extreme measures. He hid his page in a\n",
      "closet of his wife’s bedchamber, and, rising during her first sleep,\n",
      "left empty his own place beside her, went out softly, double-locked the\n",
      "door, and listened attentively to hear what would happen.\n",
      "\n",
      "He had not been listening thus for ten minutes when he heard a great\n",
      "noise in the room, and the page trying in vain to appease it. The\n",
      "marquis hoped that he might succeed, but the noise increasing, showed\n",
      "him that he was again to be disappointed; soon came cries for help, for\n",
      "the marquise could not ring, the bell-ropes having been lifted out of\n",
      "her reach, and no one answering her cries, he heard her spring from her\n",
      "high bed, run to the door, and finding it locked rush to the window,\n",
      "which she tried to open: the scene had come to its climax.\n",
      "\n",
      "The marquis decided to go in, lest some tragedy should happen, or lest\n",
      "his wife’s screams should reach some belated passer-by, who next day\n",
      "would make him the talk of the town. Scarcely did the marquise behold\n",
      "him when she threw herself into his arms, and pointing to the page,\n",
      "said:—\n",
      "\n",
      "\"Well, monsieur, will you still hesitate to free me from this insolent\n",
      "wretch?\"\n",
      "\n",
      "\"Yes, madame,\" replied the marquis; \"for this insolent wretch has been\n",
      "acting for the last three months not only with my sanction but even by\n",
      "my orders.\"\n",
      "\n",
      "The marquise remained stupefied. Then the marquis, without sending away\n",
      "the page, gave his wife an explanation of all that had passed, and\n",
      "besought her to yield to his desire of obtaining a successor, whom he\n",
      "would regard as his own child, so long as it was hers; but young though\n",
      "she was, the marquise answered with a dignity unusual at her age, that\n",
      "his power over her had the limits that were set to it by law, and not\n",
      "those that it might please him to set in their place, and that however\n",
      "much she might wish to do what might be his pleasure, she would yet\n",
      "never obey him at the expense of her soul and her honour.\n",
      "\n",
      "So positive an answer, while it filled her husband with despair, proved\n",
      "to him that he must renounce the hope of obtaining an heir; but since\n",
      "the page was not to blame for this, he fulfilled the promise that he had\n",
      "made, bought him a regiment, and resigned himself to having the most\n",
      "virtuous wife in France. His repentance was not, however, of long\n",
      "duration; he died at the end of three months, after having confided to\n",
      "his friend, the Marquis d’Urban, the cause of his sorrows.\n",
      "\n",
      "The Marquis d’Urban had a son of marriageable age; he thought that he\n",
      "could find nothing more suitable for him than a wife whose virtue had\n",
      "come triumphantly through such a trial: he let her time of mourning\n",
      "pass, and then presented the young Marquis d’Urban, who succeeded in\n",
      "making his attentions acceptable to the beautiful widow, and soon became\n",
      "her husband. More fortunate than his predecessor, the Marquis d’Urban\n",
      "had three heirs to oppose to his collaterals, when, some two years and a\n",
      "half later, the Chevalier de Bouillon arrived at the capital of the\n",
      "county of Venaissin.\n",
      "\n",
      "The Chevalier de Bouillon was a typical rake of the period, handsome,\n",
      "young, and well-grown; the nephew of a cardinal who was influential at\n",
      "Rome, and proud of belonging to a house which had privileges of\n",
      "suzerainty. The chevalier, in his indiscreet fatuity, spared no woman;\n",
      "and his conduct had given some scandal in the circle of Madame de\n",
      "Maintenon, who was rising into power. One of his friends, having\n",
      "witnessed the displeasure exhibited towards him by Louis XIV, who was\n",
      "beginning to become devout, thought to do him a service by warning him\n",
      "that the king \"gardait une dent\" against him. [ Translator’s\n",
      "note.—\"Garder une dent,\" that is, to keep up a grudge, means literally\n",
      "\"to keep a tooth\" against him.]\n",
      "\n",
      "\"Pardieu!\" replied the chevalier, \"I am indeed unlucky when the only\n",
      "tooth left to him remains to bite me.\"\n",
      "\n",
      "This pun had been repeated, and had reached Louis XIV, so that the\n",
      "chevalier presently heard, directly enough this time, that the king\n",
      "desired him to travel for some years. He knew the danger of\n",
      "neglecting—such intimations, and since he thought the country after all\n",
      "preferable to the Bastille, he left Paris, and arrived at Avignon,\n",
      "surrounded by the halo of interest that naturally attends a handsome\n",
      "young persecuted nobleman.\n",
      "\n",
      "The virtue of Madame d’Urban was as much cried up at Avignon as the\n",
      "ill-behaviour of the chevalier had been reprobated in Paris. A\n",
      "reputation equal to his own, but so opposite in kind, could not fail to\n",
      "be very offensive to him, therefore he determined immediately upon\n",
      "arriving to play one against the other.\n",
      "\n",
      "Nothing was easier than the attempt. M. d’Urban, sure of his wife’s\n",
      "virtue, allowed her entire liberty; the chevalier saw her wherever he\n",
      "chose to see her, and every time he saw her found means to express a\n",
      "growing passion. Whether because the hour had come for Madame d’Urban,\n",
      "or whether because she was dazzled by the splendour of the chevalier’s\n",
      "belonging to a princely house, her virtue, hitherto so fierce, melted\n",
      "like snow in the May sunshine; and the chevalier, luckier than the poor\n",
      "page, took the husband’s place without any attempt on Madame d’Urban’s\n",
      "part to cry for help.\n",
      "\n",
      "As all the chevalier desired was public triumph, he took care to make\n",
      "the whole town acquainted at once with his success; then, as some\n",
      "infidels of the neighbourhood still doubted, the chevalier ordered one\n",
      "of his servants to wait for him at the marquise’s door with a lantern\n",
      "and a bell. At one in the morning, the chevalier came out, and the\n",
      "servant walked before him, ringing the bell. At this unaccustomed sound,\n",
      "a great number of townspeople, who had been quietly asleep, awoke, and,\n",
      "curious to see what was happening, opened their windows. They beheld the\n",
      "chevalier, walking gravely behind his servant, who continued to light\n",
      "his master’s way and to ring along the course of the street that lay\n",
      "between Madame d’Urban’s house and his own. As he had made no mystery to\n",
      "anyone of his love affair, nobody took the trouble even to ask him\n",
      "whence he came. However, as there might possibly be persons still\n",
      "unconvinced, he repeated this same jest, for his own satisfaction, three\n",
      "nights running; so that by the morning of the fourth day nobody had any\n",
      "doubts left.\n",
      "\n",
      "As generally happens in such cases, M. d’Urban did not know a word of\n",
      "what was going on until the moment when his friends warned him that he\n",
      "was the talk of the town. Then he forbade his wife to see her lover\n",
      "again. The prohibition produced the usual results: on the morrow, as,\n",
      "soon as M. d’Urban had gone out, the marquise sent for the chevalier to\n",
      "inform him of the catastrophe in which they were both involved; but she\n",
      "found him far better prepared than herself for such blows, and he tried\n",
      "to prove to her, by reproaches for her imprudent conduct, that all this\n",
      "was her fault; so that at last the poor woman, convinced that it was she\n",
      "who had brought these woes upon them, burst into tears. Meanwhile, M.\n",
      "d’Urban, who, being jealous for the first time, was the more seriously\n",
      "so, having learned that the chevalier was with his wife, shut the doors,\n",
      "and posted himself in the ante-chamber with his servants, in order to\n",
      "seize him as he came out. But the chevalier, who had ceased to trouble\n",
      "himself about Madame d’Urban’s tears, heard all the preparations, and,\n",
      "suspecting some ambush, opened the window, and, although it was one\n",
      "o’clock in the afternoon and the place was full of people, jumped out of\n",
      "the window into the street, and did not hurt himself at all, though the\n",
      "height was twenty feet, but walked quietly home at a moderate pace.\n",
      "\n",
      "The same evening, the chevalier, intending to relate his new adventure\n",
      "in all its details, invited some of his friends to sup with him at the\n",
      "pastrycook Lecoq’s. This man, who was a brother of the famous Lecoq of\n",
      "the rue Montorgueil, was the cleverest eating-house-keeper in Avignon;\n",
      "his own unusual corpulence commended his cookery, and, when he stood at\n",
      "the door, constituted an advertisement for his restaurant. The good man,\n",
      "knowing with what delicate appetites he had to deal, did his very best\n",
      "that evening, and that nothing might be wanting, waited upon his guests\n",
      "himself. They spent the night drinking, and towards morning the\n",
      "chevalier and his companions, being then drunk, espied their host\n",
      "standing respectfully at the door, his face wreathed in smiles. The\n",
      "chevalier called him nearer, poured him out a glass of wine and made him\n",
      "drink with them; then, as the poor wretch, confused at such an honour,\n",
      "was thanking him with many bows, he said:—\n",
      "\n",
      "\"Pardieu, you are too fat for Lecoq, and I must make you a capon.\"\n",
      "\n",
      "This strange proposition was received as men would receive it who were\n",
      "drunk and accustomed by their position to impunity. The unfortunate\n",
      "pastry-cook was seized, bound down upon the table, and died under their\n",
      "treatment. The vice-legate being informed of the murder by one of the\n",
      "waiters, who had run in on hearing his master’s shrieks, and had found\n",
      "him, covered with blood, in the hands of his butchers, was at first\n",
      "inclined to arrest the chevalier and bring him conspicuously to\n",
      "punishment. But he was restrained by his regard for the Cardinal de\n",
      "Bouillon, the chevalier’s uncle, and contented himself with warning the\n",
      "culprit that unless he left the town instantly he would be put into the\n",
      "hands of the authorities. The chevalier, who was beginning to have had\n",
      "enough of Avignon, did not wait to be told twice, ordered the wheels of\n",
      "his chaise to be greased and horses to be brought. In the interval\n",
      "before they were ready the fancy took him to go and see Madame d’Urban\n",
      "again.\n",
      "\n",
      "As the house of the marquise was the very last at which, after the\n",
      "manner of his leaving it the day before, the chevalier was expected at\n",
      "such an hour, he got in with the greatest ease, and, meeting a\n",
      "lady’s-maid, who was in his interests, was taken to the room where the\n",
      "marquise was. She, who had not reckoned upon seeing the chevalier again,\n",
      "received him with all the raptures of which a woman in love is capable,\n",
      "especially when her love is a forbidden one. But the chevalier soon put\n",
      "an end to them by announcing that his visit was a visit of farewell, and\n",
      "by telling her the reason that obliged him to leave her. The marquise\n",
      "was like the woman who pitied the fatigue of the poor horses that tore\n",
      "Damien limb from limb; all her commiseration was for the chevalier, who\n",
      "on account of such a trifle was being forced to leave Avignon. At last\n",
      "the farewell had to be uttered, and as the chevalier, not knowing what\n",
      "to say at the fatal moment, complained that he had no memento of her,\n",
      "the marquise took down the frame that contained a portrait of herself\n",
      "corresponding with one of her husband, and tearing out the canvas,\n",
      "rolled, it up and gave it to the chevalier. The latter, so far from\n",
      "being touched by this token of love, laid it down, as he went away, upon\n",
      "a piece of furniture, where the marquise found it half an hour later.\n",
      "She imagined that his mind being so full of the original, he had\n",
      "forgotten the copy, and representing to herself the sorrow which the\n",
      "discovery of this forgetfulness would cause him, she sent for a servant,\n",
      "gave him the picture, and ordered him to take horse and ride after the\n",
      "chevalier’s chaise. The man took a post-horse, and, making great speed,\n",
      "perceived the fugitive in the distance just as the latter had finished\n",
      "changing horses. He made violent signs and shouted loudly, in order to\n",
      "stop the postillion. But the postillion having told his fare that he saw\n",
      "a man coming on at full speed, the chevalier supposed himself to be\n",
      "pursued, and bade him go on as fast as possible. This order was so well\n",
      "obeyed that the unfortunate servant only came up with the chaise a\n",
      "league and a half farther on; having stopped the postillion, he got off\n",
      "his horse, and very respectfully presented to the chevalier the picture\n",
      "which he had been bidden to bring him. But the chevalier, having\n",
      "recovered from his first alarm, bade him go about his business, and take\n",
      "back the portrait—which was of no use to him—to the sender. The servant,\n",
      "however, like a faithful messenger, declared that his orders were\n",
      "positive, and that he should not dare go back to Madame d’Urban without\n",
      "fulfilling them. The chevalier, seeing that he could not conquer the\n",
      "man’s determination, sent his postillion to a farrier, whose house lay\n",
      "on the road, for a hammer and four nails, and with his own hands nailed\n",
      "the portrait to the back of his chaise; then he stepped in again, bade\n",
      "the postillion whip up his horses, and drove away, leaving Madame\n",
      "d’Urban’s messenger greatly astonished at the manner in which the\n",
      "chevalier had used his mistress’s portrait.\n",
      "\n",
      "At the next stage, the postillion, who was going back, asked for his\n",
      "money, and the chevalier answered that he had none. The postillion\n",
      "persisted; then the chevalier got out of his chaise, unfastened Madame\n",
      "d’Urban’s portrait, and told him that he need only put it up for sale in\n",
      "Avignon and declare how it had come into his possession, in order to\n",
      "receive twenty times the price of his stage; the postillion, seeing that\n",
      "nothing else was to be got out of the chevalier, accepted the pledge,\n",
      "and, following his instructions precisely, exhibited it next morning at\n",
      "the door of a dealer in the town, together with an exact statement of\n",
      "the story. The picture was bought back the same day for twenty-five\n",
      "Louis.\n",
      "\n",
      "As may be supposed, the adventure was much talked of throughout the\n",
      "town. Next day, Madame d’Urban disappeared, no one knew whither, at the\n",
      "very time when the relatives of the marquis were met together and had\n",
      "decided to ask the king for a ’lettre-de-cachet’. One of the gentlemen\n",
      "present was entrusted with the duty of taking the necessary steps; but\n",
      "whether because he was not active enough, or whether because he was in\n",
      "Madame d’Urban’s interests, nothing further was heard in Avignon of any\n",
      "consequences ensuing from such steps. In the meantime, Madame d’Urban,\n",
      "who had gone to the house of an aunt, opened negotiations with her\n",
      "husband that were entirely successful, and a month after this adventure\n",
      "she returned triumphantly to the conjugal roof.\n",
      "\n",
      "Two hundred pistoles, given by the Cardinal de Bouillon, pacified the\n",
      "family of the unfortunate pastry-cook, who at first had given notice of\n",
      "the affair to the police, but who soon afterwards withdrew their\n",
      "complaint, and gave out that they had taken action too hastily on the\n",
      "strength of a story told in joke, and that further inquiries showed\n",
      "their relative to have died of an apoplectic stroke.\n",
      "\n",
      "Thanks—to this declaration, which exculpated the Chevalier de Bouillon\n",
      "in the eyes of the king, he was allowed, after travelling for two years\n",
      "in Italy and in Germany, to return undisturbed to France.\n",
      "\n",
      "Thus ends, not the family of Ganges, but the commotion which the family\n",
      "made in the world. From time to time, indeed, the playwright or the\n",
      "novelist calls up the pale and bloodstained figure of the marquise to\n",
      "appear either on the stag\n"
     ]
    }
   ],
   "source": [
    "print book_corpus[0].text[-19350:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'book_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7c248ecf8581>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Preprocess the text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbook_corpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mbook\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'book_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# Preprocess the text\n",
    "for book in book_corpus:\n",
    "    print book[1]\n",
    "    book.clean()\n",
    "    book.lemmatize()\n",
    "    book.stem()\n",
    "    print book[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to split a book into parsed sentences\n",
    "def book_to_sentences(book, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(book.text.encode(\"ascii\",\"ignore\").strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( book_to_wordlist( raw_sentence, remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences\n",
    "\n",
    "def book_to_wordlist(book_text, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    #  \n",
    "    #  Decode from UTF-8\n",
    "#     tbl = dict.fromkeys(i for i in xrange(sys.maxunicode)\n",
    "#               if unicodedata.category(unichr(i)).startswith('P'))\n",
    "#     book_text = book.text.translate(tbl)\n",
    "\n",
    "    #\n",
    "    # 3. Convert words to lower case and split themstring.decode('utf-8')\n",
    "    words = book_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "\n",
    "print \"Parsing sentences from training set\"\n",
    "for book in book_corpus:\n",
    "    sentences += book_to_sentences(book, tokenizer)\n",
    "    \n",
    "    \n",
    "# print \"Parsing sentences from unlabeled set\"\n",
    "# for review in unlabeled_train[\"review\"]:\n",
    "#     sentences += review_to_sentences(review, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['but',\n",
       "  'this',\n",
       "  'monsieur',\n",
       "  'of',\n",
       "  'lintendance\"',\n",
       "  '(pointing',\n",
       "  'over',\n",
       "  'his',\n",
       "  'shoulder',\n",
       "  'to',\n",
       "  'colbert,',\n",
       "  'who',\n",
       "  'if',\n",
       "  'possible,',\n",
       "  'became',\n",
       "  'paler,',\n",
       "  'behind',\n",
       "  'him)',\n",
       "  '\"has',\n",
       "  'in',\n",
       "  'his',\n",
       "  'coffers',\n",
       "  'nine',\n",
       "  'hundred',\n",
       "  'thousand',\n",
       "  'livres',\n",
       "  'of',\n",
       "  'mine.\"'],\n",
       " ['the', 'king', 'turned', 'round', 'to', 'look', 'at', 'colbert.'],\n",
       " ['\"but--\"', 'said', 'the', 'latter.'],\n",
       " ['\"monsieur,\"',\n",
       "  'continued',\n",
       "  'fouquet,',\n",
       "  'still',\n",
       "  'speaking',\n",
       "  'indirectly',\n",
       "  'to',\n",
       "  'colbert,',\n",
       "  '\"monsieur',\n",
       "  'has',\n",
       "  'received,',\n",
       "  'a',\n",
       "  'week',\n",
       "  'ago,',\n",
       "  'sixteen',\n",
       "  'hundred',\n",
       "  'thousand',\n",
       "  'livres;',\n",
       "  'he',\n",
       "  'has',\n",
       "  'paid',\n",
       "  'a',\n",
       "  'hundred',\n",
       "  'thousand',\n",
       "  'livres',\n",
       "  'to',\n",
       "  'the',\n",
       "  'guards,',\n",
       "  'sixty-four',\n",
       "  'thousand',\n",
       "  'livres',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hospitals,',\n",
       "  'twenty-five',\n",
       "  'thousand',\n",
       "  'to',\n",
       "  'the',\n",
       "  'swiss,',\n",
       "  'an',\n",
       "  'hundred',\n",
       "  'and',\n",
       "  'thirty',\n",
       "  'thousand',\n",
       "  'for',\n",
       "  'provisions,',\n",
       "  'a',\n",
       "  'thousand',\n",
       "  'for',\n",
       "  'arms,',\n",
       "  'ten',\n",
       "  'thousand',\n",
       "  'for',\n",
       "  'accidental',\n",
       "  'expenses;',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'err,',\n",
       "  'then,',\n",
       "  'in',\n",
       "  'reckoning',\n",
       "  'upon',\n",
       "  'nine',\n",
       "  'hundred',\n",
       "  'thousand',\n",
       "  'livres',\n",
       "  'that',\n",
       "  'are',\n",
       "  'left.\"'],\n",
       " ['then',\n",
       "  'turning',\n",
       "  'towards',\n",
       "  'colbert,',\n",
       "  'like',\n",
       "  'a',\n",
       "  'disdainful',\n",
       "  'head',\n",
       "  'of',\n",
       "  'office',\n",
       "  'towards',\n",
       "  'his',\n",
       "  'inferior,',\n",
       "  '\"take',\n",
       "  'care,',\n",
       "  'monsieur,\"',\n",
       "  'said',\n",
       "  'he,',\n",
       "  '\"that',\n",
       "  'those',\n",
       "  'nine',\n",
       "  'hundred',\n",
       "  'thousand',\n",
       "  'livres',\n",
       "  'be',\n",
       "  'remitted',\n",
       "  'to',\n",
       "  'his',\n",
       "  'majesty',\n",
       "  'this',\n",
       "  'evening,',\n",
       "  'in',\n",
       "  'gold.\"'],\n",
       " ['\"but,\"',\n",
       "  'said',\n",
       "  'the',\n",
       "  'king,',\n",
       "  '\"that',\n",
       "  'will',\n",
       "  'make',\n",
       "  'two',\n",
       "  'millions',\n",
       "  'five',\n",
       "  'hundred',\n",
       "  'thousand',\n",
       "  'livres.\"'],\n",
       " ['\"sire,',\n",
       "  'the',\n",
       "  'five',\n",
       "  'hundred',\n",
       "  'thousand',\n",
       "  'livres',\n",
       "  'over',\n",
       "  'will',\n",
       "  'serve',\n",
       "  'as',\n",
       "  'pocket',\n",
       "  'money',\n",
       "  'for',\n",
       "  'his',\n",
       "  'royal',\n",
       "  'highness.'],\n",
       " ['you',\n",
       "  'understand,',\n",
       "  'monsieur',\n",
       "  'colbert,',\n",
       "  'this',\n",
       "  'evening',\n",
       "  'before',\n",
       "  'eight',\n",
       "  'oclock.\"'],\n",
       " ['and',\n",
       "  'with',\n",
       "  'these',\n",
       "  'words,',\n",
       "  'bowing',\n",
       "  'respectfully',\n",
       "  'to',\n",
       "  'the',\n",
       "  'king,',\n",
       "  'the',\n",
       "  'superintendent',\n",
       "  'made',\n",
       "  'his',\n",
       "  'exit',\n",
       "  'backwards,',\n",
       "  'without',\n",
       "  'honoring',\n",
       "  'with',\n",
       "  'a',\n",
       "  'single',\n",
       "  'look',\n",
       "  'the',\n",
       "  'envious',\n",
       "  'man,',\n",
       "  'whose',\n",
       "  'head',\n",
       "  'he',\n",
       "  'had',\n",
       "  'just',\n",
       "  'half',\n",
       "  'shaved.'],\n",
       " ['colbert', 'tore', 'his', 'r']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-18 10:21:11,226 : INFO : collecting all words and their counts\n",
      "2017-06-18 10:21:11,229 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-06-18 10:21:11,325 : INFO : PROGRESS: at sentence #10000, processed 324064 words, keeping 29516 word types\n",
      "2017-06-18 10:21:11,388 : INFO : PROGRESS: at sentence #20000, processed 562931 words, keeping 41479 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-18 10:21:11,444 : INFO : PROGRESS: at sentence #30000, processed 760320 words, keeping 49746 word types\n",
      "2017-06-18 10:21:11,500 : INFO : PROGRESS: at sentence #40000, processed 928541 words, keeping 55250 word types\n",
      "2017-06-18 10:21:11,552 : INFO : PROGRESS: at sentence #50000, processed 1090042 words, keeping 59820 word types\n",
      "2017-06-18 10:21:11,621 : INFO : PROGRESS: at sentence #60000, processed 1246524 words, keeping 63973 word types\n",
      "2017-06-18 10:21:11,680 : INFO : PROGRESS: at sentence #70000, processed 1395229 words, keeping 67527 word types\n",
      "2017-06-18 10:21:11,727 : INFO : PROGRESS: at sentence #80000, processed 1558275 words, keeping 70709 word types\n",
      "2017-06-18 10:21:11,779 : INFO : PROGRESS: at sentence #90000, processed 1706382 words, keeping 73504 word types\n",
      "2017-06-18 10:21:11,823 : INFO : PROGRESS: at sentence #100000, processed 1846406 words, keeping 76168 word types\n",
      "2017-06-18 10:21:11,868 : INFO : PROGRESS: at sentence #110000, processed 1981586 words, keeping 78505 word types\n",
      "2017-06-18 10:21:11,918 : INFO : PROGRESS: at sentence #120000, processed 2125563 words, keeping 83159 word types\n",
      "2017-06-18 10:21:11,934 : INFO : collected 84241 word types from a corpus of 2158011 raw words and 122577 sentences\n",
      "2017-06-18 10:21:11,934 : INFO : Loading a fresh vocabulary\n",
      "2017-06-18 10:21:12,028 : INFO : min_count=40 retains 4400 unique words (5% of original 84241, drops 79841)\n",
      "2017-06-18 10:21:12,029 : INFO : min_count=40 leaves 1842042 word corpus (85% of original 2158011, drops 315969)\n",
      "2017-06-18 10:21:12,046 : INFO : deleting the raw counts dictionary of 84241 items\n",
      "2017-06-18 10:21:12,052 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2017-06-18 10:21:12,055 : INFO : downsampling leaves estimated 1260453 word corpus (68.4% of prior 1842042)\n",
      "2017-06-18 10:21:12,059 : INFO : estimated required memory for 4400 words and 300 dimensions: 12760000 bytes\n",
      "2017-06-18 10:21:12,098 : INFO : resetting layer weights\n",
      "2017-06-18 10:21:12,203 : INFO : training model with 4 workers on 4400 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2017-06-18 10:21:13,207 : INFO : PROGRESS: at 10.04% examples, 727467 words/s, in_qsize 8, out_qsize 0\n",
      "2017-06-18 10:21:14,213 : INFO : PROGRESS: at 18.82% examples, 603629 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-18 10:21:15,210 : INFO : PROGRESS: at 27.38% examples, 611454 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-18 10:21:16,217 : INFO : PROGRESS: at 38.08% examples, 605335 words/s, in_qsize 8, out_qsize 0\n",
      "2017-06-18 10:21:17,224 : INFO : PROGRESS: at 48.12% examples, 625993 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-18 10:21:18,224 : INFO : PROGRESS: at 60.73% examples, 642595 words/s, in_qsize 8, out_qsize 0\n",
      "2017-06-18 10:21:19,240 : INFO : PROGRESS: at 72.13% examples, 658181 words/s, in_qsize 6, out_qsize 1\n",
      "2017-06-18 10:21:20,242 : INFO : PROGRESS: at 83.26% examples, 666491 words/s, in_qsize 6, out_qsize 0\n",
      "2017-06-18 10:21:21,240 : INFO : PROGRESS: at 96.25% examples, 676904 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-18 10:21:21,483 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-06-18 10:21:21,490 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-18 10:21:21,494 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-18 10:21:21,502 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-18 10:21:21,503 : INFO : training on 10790055 raw words (6302675 effective words) took 9.3s, 677933 effective words/s\n",
      "2017-06-18 10:21:21,506 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-06-18 10:21:21,571 : INFO : saving Word2Vec object under 300features_40min_word_count_10context.npy, separately None\n",
      "2017-06-18 10:21:21,573 : INFO : not storing attribute syn0norm\n",
      "2017-06-18 10:21:21,575 : INFO : not storing attribute cum_table\n",
      "2017-06-18 10:21:21,648 : INFO : saved 300features_40min_word_count_10context.npy\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print \"Training model...\"\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \n",
    "                          size=num_features, min_count = min_word_count, \n",
    "                          window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = str(num_features)+'features_'+str(min_word_count)+'min_word_count_'+str(context)+'context.npy'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sword'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"king queen sword\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "test_string = 'sword'\n",
    "if test_string in model.wv.index2word:\n",
    "    print 'True'\n",
    "else:\n",
    "    print 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('duke', 0.7709444761276245)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"king\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031802841"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['sword'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031802841"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['sword'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # Make sure that numpy is imported\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    print words[:10]\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(books, model, num_features):\n",
    "    # Given a set of books (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    bookFeatureVecs = np.zeros((len(books),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for book in books:\n",
    "        # Print a status message every other book\n",
    "        if counter%1. == 0.:\n",
    "            print \"Book %d of %d\" % (counter, len(books))\n",
    "        # \n",
    "        # Call the function (defined above) that makes average feature vectors\n",
    "        bookFeatureVecs[counter] = makeFeatureVec(book, model, num_features)\n",
    "        #\n",
    "        # Increment the counter\n",
    "        counter = counter + 1\n",
    "    return bookFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 0 of 8\n",
      "None\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "iter index too large",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-451bb3e09912>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetAvgFeatureVecs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook_corpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-3a73ed515d4d>\u001b[0m in \u001b[0;36mgetAvgFeatureVecs\u001b[1;34m(books, model, num_features)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# Call the function (defined above) that makes average feature vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mbookFeatureVecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakeFeatureVec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# Increment the counter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-3a73ed515d4d>\u001b[0m in \u001b[0;36mmakeFeatureVec\u001b[1;34m(words, model, num_features)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Loop over each word in the review and, if it is in the model's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# vocaublary, add its feature vector to the total\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex2word_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mnwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnwords\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: iter index too large"
     ]
    }
   ],
   "source": [
    "getAvgFeatureVecs(book_corpus, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quite unfi\n",
      "her lover \n",
      "of the kin\n",
      "\n",
      "“They des\n",
      "“How so?”\n",
      "\n",
      "but percei\n",
      "even bowin\n",
      "catching a\n"
     ]
    }
   ],
   "source": [
    "for book in book_corpus:\n",
    "    print book.text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'quite', u'unfitted,', u'turned', u'eyes', u'towards', u'france,', u'victorious', u'fetes', u'rejoicings', u'awaiting']\n",
      "Book 0 of 8\n",
      "Book 1 of 8\n",
      "Book 2 of 8\n",
      "Book 3 of 8\n",
      "Book 4 of 8\n",
      "Book 5 of 8\n",
      "Book 6 of 8\n",
      "Book 7 of 8\n"
     ]
    }
   ],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors for training and testing sets,\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "\n",
    "clean_train_books = []\n",
    "for book in book_corpus:\n",
    "    clean_train_books.append( book_to_wordlist( book.text, remove_stopwords=True ))\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_books, model, num_features )\n",
    "\n",
    "# print \"Creating average feature vecs for test reviews\"\n",
    "# clean_test_books = []\n",
    "# for book in book_corpus:\n",
    "#     print book\n",
    "#     clean_test_books.append( book_to_wordlist( book.text, remove_stopwords=True ))\n",
    "\n",
    "# testDataVecs = getAvgFeatureVecs( clean_test_book, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'quite',\n",
       " u'unfitted,',\n",
       " u'turned',\n",
       " u'eyes',\n",
       " u'towards',\n",
       " u'france,',\n",
       " u'victorious',\n",
       " u'fetes',\n",
       " u'rejoicings',\n",
       " u'awaiting']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_books[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00819087,  0.00242723, -0.00023242,  0.00605961, -0.0115401 ,\n",
       "        0.0226951 ,  0.00960517, -0.01059535,  0.01748   ,  0.00315369,\n",
       "       -0.00691469, -0.02866292, -0.01269055,  0.00380171, -0.01082311,\n",
       "        0.01059669, -0.01380262, -0.01193288, -0.00955732, -0.04420404,\n",
       "       -0.02917563,  0.01162744,  0.02712551,  0.01107198,  0.00495543,\n",
       "        0.02217433, -0.02694823, -0.05252416, -0.0280789 , -0.03110444,\n",
       "       -0.01409325,  0.04262873,  0.00611702,  0.00018216,  0.00775476,\n",
       "        0.00683201,  0.01443463,  0.00042482, -0.02677386, -0.02441705,\n",
       "        0.00968186, -0.0175599 , -0.01889522, -0.00632703, -0.015441  ,\n",
       "       -0.01178054, -0.01588683, -0.00518356,  0.01394426,  0.00999474,\n",
       "       -0.01085228,  0.01466012,  0.00159153,  0.00867865,  0.00217163,\n",
       "       -0.00634632,  0.00178571, -0.02554685, -0.0084363 , -0.02391442,\n",
       "       -0.000587  ,  0.00486024,  0.0259176 , -0.03461701,  0.02162339,\n",
       "       -0.01839769, -0.00831208,  0.03377576,  0.05346158, -0.01614451,\n",
       "       -0.00153653,  0.04687224, -0.01682305, -0.00311388,  0.00045077,\n",
       "        0.00072967,  0.0106708 ,  0.01064813,  0.00708467,  0.04663376,\n",
       "       -0.02388252, -0.0248508 ,  0.04437696,  0.02571618,  0.00410808,\n",
       "       -0.00310546, -0.0194851 , -0.03476832,  0.03586989,  0.00376086,\n",
       "       -0.01262534, -0.01441331, -0.02514482,  0.02425506,  0.01401521,\n",
       "       -0.05354023, -0.00455789,  0.02067112, -0.01562868,  0.02683563,\n",
       "       -0.00653457,  0.02004415,  0.00650182,  0.00526529,  0.01538164,\n",
       "        0.00162246,  0.01130935,  0.02050849,  0.00132173, -0.01468776,\n",
       "       -0.01867027, -0.01768681,  0.02040887,  0.00958168,  0.01636194,\n",
       "        0.00075554, -0.02294105,  0.03464566,  0.01464748,  0.0027439 ,\n",
       "        0.01244105, -0.00407166, -0.01683905, -0.00529408,  0.00353685,\n",
       "       -0.00060972,  0.01943208,  0.01596604,  0.01211672, -0.01146276,\n",
       "        0.00057652, -0.00706015,  0.02285466, -0.00412588, -0.00682479,\n",
       "        0.00789091, -0.00946466,  0.00959996, -0.02236741,  0.01315183,\n",
       "        0.00644395,  0.00405059,  0.01435906, -0.01444207,  0.02712581,\n",
       "        0.01955122,  0.00338371,  0.02284406, -0.00092224, -0.02362955,\n",
       "        0.00939353,  0.01901418,  0.00962829,  0.01817928, -0.0129239 ,\n",
       "        0.0239138 ,  0.00857248, -0.01201322,  0.02336429,  0.00438176,\n",
       "       -0.00676469,  0.01033166,  0.0065912 , -0.01733266, -0.00198213,\n",
       "        0.0215704 , -0.01750473,  0.00066494, -0.00927971, -0.00856691,\n",
       "        0.01493815, -0.00505155,  0.00326321, -0.04334551,  0.04956508,\n",
       "        0.01333453, -0.00565614,  0.00568008,  0.00568481, -0.04573315,\n",
       "        0.01576817,  0.00222723, -0.01847156,  0.01160354, -0.00985632,\n",
       "        0.00388939, -0.02594085,  0.01000038, -0.00342468, -0.01258829,\n",
       "       -0.00138637, -0.0021429 ,  0.01251797,  0.00512839,  0.00639823,\n",
       "        0.01917115, -0.00100155, -0.00657624,  0.00864728, -0.00734708,\n",
       "        0.00597263,  0.01834465, -0.00355473, -0.00159377, -0.01806218,\n",
       "        0.00438005, -0.00216913, -0.01733775, -0.01157931, -0.02316407,\n",
       "       -0.00100747, -0.00429721, -0.00125687, -0.00224824,  0.00645835,\n",
       "       -0.0040773 ,  0.01422349,  0.00215758,  0.01896815, -0.00385405,\n",
       "        0.01458305, -0.00651753, -0.01019094,  0.03030861, -0.0159103 ,\n",
       "       -0.03489878, -0.00112844,  0.00917662, -0.01879047, -0.0025509 ,\n",
       "        0.00626067,  0.00784059,  0.02401467, -0.02708812, -0.0320955 ,\n",
       "        0.0274997 , -0.00660571, -0.03441087, -0.00210298,  0.03044923,\n",
       "        0.0135768 ,  0.01293177, -0.04370458,  0.02252383, -0.01916879,\n",
       "        0.00957356, -0.00694985,  0.01926599,  0.02871339, -0.0033269 ,\n",
       "       -0.00880004, -0.02073145, -0.01662603,  0.02566598,  0.03100988,\n",
       "        0.01876872, -0.01954869, -0.02055099,  0.03298102, -0.01331369,\n",
       "       -0.00933449,  0.00120258, -0.00787027, -0.01727666,  0.00992268,\n",
       "        0.01029343, -0.01160587, -0.0049882 , -0.00829746, -0.01785317,\n",
       "        0.00392625, -0.00210664,  0.02149379, -0.00759142, -0.03033397,\n",
       "        0.01100561, -0.00319953,  0.00885578, -0.01529645,  0.00377104,\n",
       "       -0.01373379,  0.01684901,  0.00340808, -0.00969426,  0.00019125,\n",
       "       -0.00473697, -0.00139127, -0.00413038, -0.01511904, -0.01238347,\n",
       "        0.00517346, -0.00395935, -0.00953527, -0.00392446,  0.00087885,\n",
       "       -0.00655727, -0.01586843,  0.02073559, -0.02922841,  0.00610602], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataVecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def rewrite_my_text(my_text, model):\n",
    "    wordlist = model.wv.index2word\n",
    "    punctuation = '.?!\",;:()'.split()\n",
    "    for mark in punctuation:\n",
    "        my_text = my_text.replace(mark, ' ' + mark)\n",
    "    lst = my_text.split()\n",
    "    lst_new = []\n",
    "    for word in lst:\n",
    "        if (len(word) > 3) and (word in wordlist):\n",
    "            word = word.strip()\n",
    "            lst_new.append(model.most_similar(word)[random.randint(0,3)][0])\n",
    "        else:\n",
    "            lst_new.append(word)\n",
    "    ret = ' '.join(lst_new)\n",
    "    for mark in punctuation:\n",
    "        ret = ret.replace(' ' + mark, mark)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your time, is limited, so don\\'t waste it even, anybody else\\'s future Don\\'t be trapped by dogma - broken is suffering showed the results of other. people\\'s thinking. Don\\'t let the crowd of others\\' opinions drown out \"your own inner low And character important, had the strength to rejoin yourself grief and intuition.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For fun\n",
    "MyText = \"Your time is limited, so don't waste it living someone else's life. Don't be trapped by dogma - which is living with the results of other people's thinking. Don't let the noise of others' opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition.\"\n",
    "rewrite_my_text(MyText, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
